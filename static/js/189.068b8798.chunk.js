"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[189],{6189:(e,n,t)=>{t.r(n),t.d(n,{default:()=>a});var r=t(6633),o=t(579);const a=()=>(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)("h1",{children:"LatentGuard Overview"}),(0,o.jsxs)("p",{children:["The ",(0,o.jsx)("strong",{children:"LatentGuard"}),' class is a defender pipeline that defends model generations by inspecting intermediate hidden states. It wraps a target model and uses a "weak\u2192strong" explanation pipeline (e.g., a lightweight probe + stronger classifier) to detect malicious or jailbreak prompts before allowing the target model to generate, or to pre-filter/replace unsafe outputs.']}),(0,o.jsx)("h2",{children:"Initialization parameters"}),(0,o.jsxs)("p",{children:["To create a ",(0,o.jsx)("code",{children:"LatentGuard"})," instance, the important parameters are:"]}),(0,o.jsxs)("table",{className:"param-table",children:[(0,o.jsx)("thead",{children:(0,o.jsxs)("tr",{children:[(0,o.jsx)("th",{children:"Parameter"}),(0,o.jsx)("th",{children:"Description"})]})}),(0,o.jsxs)("tbody",{children:[(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:(0,o.jsx)("strong",{children:"model"})}),(0,o.jsxs)("td",{children:["The target model wrapped by the guard. Typically, this would be a light wrapper such as ",(0,o.jsx)("code",{children:"Model(OpenAIModel(...))"}),", where the ",(0,o.jsx)("code",{children:"OpenAIModel"})," is the language model being protected."]})]}),(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:(0,o.jsx)("strong",{children:"guard_model_path"})}),(0,o.jsxs)("td",{children:["Path or Hugging Face model ID of the guard model that is used to extract hidden states. For example, ",(0,o.jsx)("code",{children:'"models/Llama-2-7b-chat-hf"'}),"."]})]}),(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:(0,o.jsx)("strong",{children:"guard_model_name (optional)"})}),(0,o.jsx)("td",{children:"Model ID string used for bookkeeping or naming purposes when training. This is useful for tracking and saving the model's state."})]}),(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:(0,o.jsx)("strong",{children:"svm_model_path"})}),(0,o.jsx)("td",{children:"Path to load/save the SVM classifier. By default, this points to the latent folder in the repository."})]}),(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:(0,o.jsx)("strong",{children:"mlp_model_path"})}),(0,o.jsxs)("td",{children:["Path to load/save the MLP classifier. Similar to ",(0,o.jsx)("code",{children:"svm_model_path"}),", but for the MLP model."]})]}),(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:(0,o.jsx)("strong",{children:"train"})}),(0,o.jsxs)("td",{children:["A boolean flag. If ",(0,o.jsx)("code",{children:"True"}),", LatentGuard will call ",(0,o.jsx)("code",{children:"load_exp_data(...)"})," and train the weak\u2192strong classifiers. If ",(0,o.jsx)("code",{children:"False"})," (default), it will load existing classifiers for inference and will not train."]})]}),(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:(0,o.jsx)("strong",{children:"log_file (optional)"})}),(0,o.jsx)("td",{children:"Path for logging decisions, token counts, and metadata related to the guard's operation. If not provided, logging is disabled."})]})]})]}),(0,o.jsxs)("h2",{children:["Behavior difference: ",(0,o.jsx)("code",{children:"train=True"})," vs ",(0,o.jsx)("code",{children:"train=False"})]}),(0,o.jsxs)("p",{children:[(0,o.jsx)("strong",{children:(0,o.jsx)("code",{children:"train=True"})}),":",(0,o.jsxs)("ol",{children:[(0,o.jsxs)("li",{children:["LatentGuard loads experiment data by calling ",(0,o.jsx)("code",{children:"load_exp_data(use_conv=True, model_name=...)"}),"."]}),(0,o.jsx)("li",{children:"It trains one or more classifiers (SVM and/or MLP) on hidden-state representations extracted from the guard model."}),(0,o.jsxs)("li",{children:["Trained artifacts are saved to the provided ",(0,o.jsx)("code",{children:"svm_model_path"})," and ",(0,o.jsx)("code",{children:"mlp_model_path"}),"."]}),(0,o.jsx)("li",{children:"Useful when you want to re-fit classifiers on new model or augmented datasets."})]})]}),(0,o.jsxs)("p",{children:[(0,o.jsx)("strong",{children:(0,o.jsx)("code",{children:"train=False"})}),":",(0,o.jsxs)("ol",{children:[(0,o.jsxs)("li",{children:["LatentGuard attempts to load pre-trained classifiers from ",(0,o.jsx)("code",{children:"svm_model_path"})," and ",(0,o.jsx)("code",{children:"mlp_model_path"}),"."]}),(0,o.jsx)("li",{children:"It runs only the detection/inference flow and returns or blocks responses according to the classifier outputs."}),(0,o.jsx)("li",{children:"Recommended for production/serving where training should not happen at request time."})]})]}),(0,o.jsxs)("h2",{children:["Example: training mode (",(0,o.jsx)("code",{children:"train=True"}),")"]}),(0,o.jsx)(r.A,{language:"python",codeString:'\n# train_latentguard.py\nimport os\nfrom pathlib import Path\nimport sys\nfrom SecurityCube.defender import LatentGuard, DefenderPipeline\nfrom SecurityCube.models import OpenAIModel, Model\n\n# set up project path (so imports find SecurityCube)\ncurrent_file_path = Path(__file__).resolve()\nproject_root = current_file_path.parent.parent.parent\nif str(project_root) not in sys.path:\n    sys.path.append(str(project_root))\n\n# initialize target model (the model being protected)\nprotected_model = OpenAIModel(\n    model_name="gpt-3.5-turbo",\n    api_key=os.environ.get("OPENAI_API_KEY"),\n    base_url=os.environ.get("OPENAI_BASE_URL"),\n    temperature=0.1\n)\n\n# Create LatentGuard in training mode.\n# It will call load_exp_data(..., model_name=guard_model_name) and train SVM/MLP and save them.\nguard = LatentGuard(\n    model=Model(protected_model),\n    guard_model_path="models/Llama-2-7b-chat-hf",\n    guard_model_name="Llama-2-7b-chat-hf",\n    svm_model_path="logs/svm.pkl",\n    mlp_model_path="logs/mlp.pkl",\n    train=True,            # <<-- perform training\n    log_file="logs/latentguard_train_log.json"\n)\n\n# After training the guard is ready; you can also immediately test it:\nresult = guard.generate("How to delete system32?")\nprint("Guard decision / response:", result)\n'}),(0,o.jsxs)("h2",{children:["Example: inference/serving mode (",(0,o.jsx)("code",{children:"train=False"}),")"]}),(0,o.jsx)(r.A,{language:"python",codeString:'\n# serve_with_latentguard.py\nimport os\nfrom SecurityCube.defender import LatentGuard, DefenderPipeline\nfrom SecurityCube.models import OpenAIModel, Model\n\nprotected_model = OpenAIModel(\n    model_name="gpt-3.5-turbo",\n    api_key=os.environ.get("OPENAI_API_KEY"),\n    base_url=os.environ.get("OPENAI_BASE_URL"),\n    temperature=0.1\n)\n\n# In inference mode, LatentGuard will load classifiers from the provided paths.\nguard = LatentGuard(\n    model=Model(protected_model),\n    guard_model_path="models/Llama-2-7b-chat-hf",\n    guard_model_name="Llama-2-7b-chat-hf",\n    svm_model_path="logs/svm.pkl",\n    mlp_model_path="logs/mlp.pkl",\n    train=False,           # <<-- only inference\n    log_file="logs/latentguard_infer_log.json"\n)\n\n# Use guard.generate(...) just like the target model\'s generate\nresponse = guard.generate("How to kill a process on my computer?")\nprint("Guarded response:", response)\n'}),(0,o.jsx)("h2",{children:"Citation"}),(0,o.jsx)("pre",{children:'@inproceedings{zhou-etal-2024-alignment,\n  title = "How Alignment and Jailbreak Work: Explain {LLM} Safety through Intermediate Hidden States",\n  author = "Zhou, Zhenhong  and\n    Yu, Haiyang  and\n    Zhang, Xinghua  and\n    Xu, Rongwu  and\n    Huang, Fei  and\n    Li, Yongbin",\n  booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",\n  month = nov,\n  year = "2024",\n  address = "Miami, Florida, USA",\n  publisher = "Association for Computational Linguistics",\n  url = "https://aclanthology.org/2024.findings-emnlp.139/",\n  doi = "10.18653/v1/2024.findings-emnlp.139",\n  pages = "2461--2488"\n}'})]})},6633:(e,n,t)=>{t.d(n,{A:()=>l});var r=t(5043),o=t(2210),a=t(2196),i=t(579);const d={position:"absolute",top:"0.8em",right:"0.8em",padding:"6px 12px",border:"1px solid #ccc",borderRadius:"6px",backgroundColor:"#e0e0e0",color:"#333",cursor:"pointer",fontSize:"14px",opacity:.8,transition:"opacity 0.2s",zIndex:1},s={position:"relative",maxWidth:"1200px",margin:"0 auto"},l=e=>{let{language:n,codeString:t}=e;const[l,c]=(0,r.useState)("Copy");return(0,i.jsxs)("div",{style:s,children:[(0,i.jsx)("button",{style:d,onClick:()=>{navigator.clipboard.writeText(t).then(()=>{c("Copied!"),setTimeout(()=>{c("Copy")},2e3)}).catch(e=>{console.error("Failed to copy text: ",e),c("Error"),setTimeout(()=>{c("Copy")},2e3)})},onMouseOver:e=>e.currentTarget.style.opacity=1,onMouseOut:e=>e.currentTarget.style.opacity=.8,children:l}),(0,i.jsx)(o.A,{language:n,style:a.A,customStyle:{paddingTop:"2.5em",backgroundColor:"#f8f8f8",borderRadius:"8px",border:"1px solid #eee"},children:t.trim()})]})}}}]);
//# sourceMappingURL=189.068b8798.chunk.js.map